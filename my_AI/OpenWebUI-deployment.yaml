apiVersion: v1
kind: Service
metadata:
  name: open-webui-service
  labels:
    app: my-AI
spec:
  ports:
    - port: 8080
  selector:
    app: my-AI
    tier: backend
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: open-webui-deployment
  labels:
    app: my-AI
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-AI
      tier: backend
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: my-AI
        tier: backend
    spec:
      containers:
        - image: ghcr.io/open-webui/open-webui:v0.6.5
          name: open-webui
          env:
            - name: OLLAMA_BASE_URL
              value: "http://ollama-service.default.svc.cluster.local:11434"
            - name: ENABLE_RAG_WEB_SEARCH
              value: "True"
            - name: ENABLE_RAG_LOCAL_WEB_FETCH
              value: "True"
            - name: RAG_WEB_SEARCH_ENGINE
              value: "searxng"
            - name: SEARXNG_QUERY_URL
              value: "https://searxng.oahs.f5.si/search?q=<query>"
          ports:
            - containerPort: 8080
          volumeMounts:
            - name: open-webui-persistent-storage
              mountPath: /app/backend/data
          resources:
            limits:
              cpu: "1"
              memory: 3Gi
            requests:
              cpu: "500m"
              memory: 2Gi
      volumes:
        - name: open-webui-persistent-storage
          persistentVolumeClaim:
            claimName: open-webui-pv-claim
